{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('video_id_transcript_bulk_df_semi_clean.pkl', 'rb') as picklefile:\n",
    "    df = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('video_id_comments_bulk_df_2.pkl', 'rb') as picklefile:\n",
    "#    df2 = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>_5DXs8xxaMU</td>\n",
       "      <td>[{'text': 'yeah I really don't understand why'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>DNrMPF3I_bs</td>\n",
       "      <td>[{'text': '[Music]'}, {'text': 'it's the Unite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>TwN8soCzjPM</td>\n",
       "      <td>[{'text': 'testing one two I don't know if thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>8OMUdYoIJhI</td>\n",
       "      <td>[{'text': 'hello again I'm Walter to continue ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>xk_MHfOAfRQ</td>\n",
       "      <td>[{'text': 'oh whoa who are you I'm Julie from ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           url                                         transcript\n",
       "0  _5DXs8xxaMU  [{'text': 'yeah I really don't understand why'...\n",
       "1  DNrMPF3I_bs  [{'text': '[Music]'}, {'text': 'it's the Unite...\n",
       "3  TwN8soCzjPM  [{'text': 'testing one two I don't know if thi...\n",
       "4  8OMUdYoIJhI  [{'text': 'hello again I'm Walter to continue ...\n",
       "5  xk_MHfOAfRQ  [{'text': 'oh whoa who are you I'm Julie from ..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move to II\n",
    "#df.reset_index(inplace=True)\n",
    "df.rename(columns={'url': 'video_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemmer=LancasterStemmer()\n",
    "#porter=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "englishStemmer=SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "def stemComment(comment_line):\n",
    "    token_words=word_tokenize(comment_line)\n",
    "    stem_line=[]\n",
    "    for word in token_words:\n",
    "        stem_line.append(englishStemmer.stem(word))\n",
    "        stem_line.append(\" \")\n",
    "    return \"\".join(stem_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stop_words(comment_line):\n",
    "    token_words=word_tokenize(str(comment_line))\n",
    "    filtered_comment_line = [w for w in token_words if not w in stop_words] \n",
    "    \n",
    "    return \" \".join(filtered_comment_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transcript'] = df['transcript'].map(remove_stop_words).map(alphanumeric).map(punc_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/29270917/removing-custom-stop-words-form-a-phrase-in-python\n",
    "my_stop_words_lst = ['music', 'applause', 'text', 'br', 'https', 'http', 'youtu', 'href', 'com', 'video', 'www', 'youtube', \n",
    "                    'watch', 'nice', 'don', 'shall', 'virus', 'just', 'corona', 'coronavirus', 'covid',\n",
    "                     'love', 'like', \n",
    "                     'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',\n",
    "                     'yeah', 'right', 'na', 'oh', 'think', 'got', 'say', 'want', 'thing',\n",
    "                     'hey', 'fuck', 'motherfucker', 'subscribed', 'okay',\n",
    "                     'subscribe', 'subscriber', 'subscribing', 'subscribers', 'please', 'make', 'thank', 'channel', \n",
    "                     'um', ' yo', 'uh'\n",
    "                    ]\n",
    "\n",
    "for w in my_stop_words_lst:\n",
    "    pattern = r'\\b'+w+r'\\b'\n",
    "    custom_stop = lambda x: re.sub(pattern, ' ', x)\n",
    "    df['transcript'] = df['transcript'].map(custom_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemSentence('Greetings from UK.. I love your videos' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transcript'] = df['transcript'].map(stemComment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>_5DXs8xxaMU</td>\n",
       "      <td>i realli n t understand everybodi n t follow r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>DNrMPF3I_bs</td>\n",
       "      <td>s unit state europ i m greg shapiro american n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>TwN8soCzjPM</td>\n",
       "      <td>test one two i n t know gon work be cool i bou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>8OMUdYoIJhI</td>\n",
       "      <td>hello i m walter continu seri co vid public se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>xk_MHfOAfRQ</td>\n",
       "      <td>whoa i m juli four month futur actual tell s g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                         transcript\n",
       "0  _5DXs8xxaMU  i realli n t understand everybodi n t follow r...\n",
       "1  DNrMPF3I_bs  s unit state europ i m greg shapiro american n...\n",
       "3  TwN8soCzjPM  test one two i n t know gon work be cool i bou...\n",
       "4  8OMUdYoIJhI  hello i m walter continu seri co vid public se...\n",
       "5  xk_MHfOAfRQ  whoa i m juli four month futur actual tell s g..."
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s unit state europ i m greg shapiro american netherland remind work home that plagu shakespear wrote all king lea i lousi re part limit spread kovat some other as cousin florida hooda would this social distanc birthday is social distanc let kid play social distanc keep distanc ll show meter his club i go hous walk dog buy groceri let dog guard groceri i need guard dog i valuabl toilet paper stuff grow tree peopl s not peopl joke time global pandem i re s i ve stolen bunch peopl s joke yes s time favorit nineteen covet joke start number s lockdown dutch author announc ban public gather of peopl theatr show word show must go is go mani show cancel dutch cinema marqu that read noth case go home re provid essenti servic good for essenti servic hospit worker stay for stay home us aka grandpar call war re being call sit couch do hashtag stay home cour come the horror quarantin tweet shit get real i m give drink month sorri punctuat i m give drink month re drink may suggest quarantin ii s regular martini drink alon hous re all adapt work home expert recommend stick daili routin much possibl rememb power of posit mind the best way live moment having feel tomorrow gon shit show liter the toilet paper run ca n t spell pandem without panic good news guy found extra toilet paper anyon need and speak america great hat let s take closer look call magga meanwhil scientist should wash hand peopl i m gon stop fli hoard mask work home total rearrang life also scientist climat crisi kill million use clean power chang get work peopl way s climat chang need hire publicist in netherland prime minist prepar us larg part popul infect scientist n t chang behavior avoid infect assum you infect chang behavior avoid transmit dutch crack at and author stress import social distanc where s waldo social distanc addit go n t cove idiot defin stupid person stubborn ignor social distanc protocol stupid person hoard all groceri above strive flatten the curv learn spanish flu year ago philadelphia social distanc until late st loui it away kept infect manag america promi flatten curv never know week donald trump deni viral threat effect infect thousand or sign trump cove idiot s shift serious trump well know are bad trump issu travel ban on white countri trump mani babi boomer haha trigger millenni i ma burn coal forc feed plastic turtl greta need spank boomer peopl age must adher strict guidelin stop global threat eat pray re togeth i woodstock republican pledg cash bailout everi singl american or much take turn trump support socialist prove wu hen ai n t noth to quit sinc china hit mileston new wuhan infect s wuhan check meanwhil germani re prepar for crisi stock sausag chee s worst case scenario and final realli help n t forget wash hand use hand satan iser rememb n t subscrib the win '"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['transcript'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Document-Term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<277x12987 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 51739 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english') \n",
    "doc_word = vectorizer.fit_transform(list(df.transcript))\n",
    "doc_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<277x12987 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 51739 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english') \n",
    "doc_word = vectorizer.fit_transform(list(df.transcript))\n",
    "doc_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(277, 12987)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(doc_word.toarray(), columns=vectorizer.get_feature_names()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = pd.DataFrame(doc_word.toarray(), index=df['video_id'], columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Semantic Analysis (LSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02138391, 0.03487296, 0.01344659, 0.01257489, 0.01037169])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa = TruncatedSVD(5)\n",
    "doc_topic = lsa.fit_transform(dtm)\n",
    "lsa.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaah</th>\n",
       "      <th>aaaaaw</th>\n",
       "      <th>aaahhh</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aasimm</th>\n",
       "      <th>ab</th>\n",
       "      <th>abacus</th>\n",
       "      <th>abanda</th>\n",
       "      <th>abandon</th>\n",
       "      <th>...</th>\n",
       "      <th>منتننتب</th>\n",
       "      <th>منني</th>\n",
       "      <th>يبخؤن</th>\n",
       "      <th>يسي</th>\n",
       "      <th>يمنن</th>\n",
       "      <th>くじょう</th>\n",
       "      <th>不好意思</th>\n",
       "      <th>法國人</th>\n",
       "      <th>阴茎病毒</th>\n",
       "      <th>ﻻهص</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>component_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>component_2</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>component_3</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>component_4</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>component_5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12987 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              aa  aaaaah  aaaaaw  aaahhh  aaron  aasimm     ab  abacus  \\\n",
       "component_1  0.0     0.0     0.0     0.0  0.001     0.0  0.003     0.0   \n",
       "component_2 -0.0    -0.0    -0.0    -0.0  0.000    -0.0 -0.001     0.0   \n",
       "component_3 -0.0    -0.0    -0.0    -0.0  0.000    -0.0  0.005    -0.0   \n",
       "component_4 -0.0    -0.0    -0.0    -0.0  0.001    -0.0  0.004     0.0   \n",
       "component_5  0.0     0.0     0.0     0.0  0.001     0.0  0.000     0.0   \n",
       "\n",
       "             abanda  abandon  ...  منتننتب  منني  يبخؤن  يسي  يمنن  くじょう  \\\n",
       "component_1   0.001    0.003  ...      0.0   0.0    0.0  0.0   0.0   0.0   \n",
       "component_2   0.005   -0.000  ...     -0.0  -0.0   -0.0 -0.0  -0.0  -0.0   \n",
       "component_3   0.001   -0.006  ...     -0.0  -0.0   -0.0 -0.0  -0.0  -0.0   \n",
       "component_4   0.001   -0.002  ...     -0.0  -0.0   -0.0 -0.0  -0.0  -0.0   \n",
       "component_5   0.002    0.000  ...      0.0   0.0    0.0  0.0   0.0   0.0   \n",
       "\n",
       "             不好意思  法國人  阴茎病毒  ﻻهص  \n",
       "component_1   0.0  0.0   0.0  0.0  \n",
       "component_2  -0.0 -0.0  -0.0 -0.0  \n",
       "component_3  -0.0 -0.0  -0.0 -0.0  \n",
       "component_4  -0.0 -0.0  -0.0 -0.0  \n",
       "component_5   0.0  0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 12987 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word = pd.DataFrame(lsa.components_.round(3),\n",
    "             index = [\"component_1\",\"component_2\", \"component_3\",\"component_4\", \"component_5\"],\n",
    "             columns = vectorizer.get_feature_names())\n",
    "topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "know, peopl, gon, time, ve, realli, come, good, look, ll, work, mean, lot, home, need, day, way, let, laughter, man, stay, talk, guy, toilet, paper, said, hand, tri, tell, world\n",
      "\n",
      "Topic  1\n",
      "laughter, fool, obvious, surpri, marfa, myka, plea, check, sub, switch, flip, tintin, visit, subscrib, penc, trump, god, comedi, buddi, defam, buta, vqe, bruno, vato, andrea, lovato, ibaka, hemic, tetherb, americana\n",
      "\n",
      "Topic  2\n",
      "toilet, paper, gon, home, stay, guy, man, clean, ass, hand, shit, cuz, hack, kid, touch, need, bore, drink, wipe, school, babi, subscrib, quarantin, ll, plea, groceri, stop, damn, glove, hell\n",
      "\n",
      "Topic  3\n",
      "know, man, gon, good, realli, money, mean, ll, codi, stuff, ve, funni, guy, littl, god, better, kind, babi, boy, bad, ta, appreci, someth, tell, comedi, subscrib, time, comedian, resort, happen\n",
      "\n",
      "Topic  4\n",
      "stay, home, subscrib, plea, song, wash, comedi, let, isol, money, happi, play, sure, spread, insid, yes, friend, birthday, famili, nto, hand, teacher, mommi, infect, togeth, meter, button, god, wrote, bore\n"
     ]
    }
   ],
   "source": [
    "display_topics(lsa, vectorizer.get_feature_names(), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.97015135e-06,  7.97015135e-06,  7.97015135e-06, ...,\n",
       "         2.55044843e-04,  7.97015135e-06,  7.97015135e-06],\n",
       "       [-1.43566278e-06, -1.43566278e-06, -1.43566278e-06, ...,\n",
       "        -4.59412088e-05, -1.43566278e-06, -1.43566278e-06],\n",
       "       [-1.84324712e-06, -1.84324712e-06, -1.84324712e-06, ...,\n",
       "        -5.89839080e-05, -1.84324712e-06, -1.84324712e-06],\n",
       "       [-5.85833527e-06, -5.85833527e-06, -5.85833527e-06, ...,\n",
       "        -1.87466729e-04, -5.85833527e-06, -5.85833527e-06],\n",
       "       [ 6.87392304e-07,  6.87392304e-07,  6.87392304e-07, ...,\n",
       "         2.19965537e-05,  6.87392304e-07,  6.87392304e-07]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component_1</th>\n",
       "      <th>component_2</th>\n",
       "      <th>component_3</th>\n",
       "      <th>component_4</th>\n",
       "      <th>component_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>_5DXs8xxaMU</td>\n",
       "      <td>0.313722</td>\n",
       "      <td>-0.037640</td>\n",
       "      <td>0.067371</td>\n",
       "      <td>-0.253653</td>\n",
       "      <td>0.093814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DNrMPF3I_bs</td>\n",
       "      <td>0.369401</td>\n",
       "      <td>-0.036863</td>\n",
       "      <td>0.036569</td>\n",
       "      <td>-0.298927</td>\n",
       "      <td>0.008293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TwN8soCzjPM</td>\n",
       "      <td>0.512953</td>\n",
       "      <td>-0.060678</td>\n",
       "      <td>0.366408</td>\n",
       "      <td>-0.085243</td>\n",
       "      <td>-0.241111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8OMUdYoIJhI</td>\n",
       "      <td>0.365220</td>\n",
       "      <td>-0.035835</td>\n",
       "      <td>0.084806</td>\n",
       "      <td>0.093842</td>\n",
       "      <td>0.099401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xk_MHfOAfRQ</td>\n",
       "      <td>0.443260</td>\n",
       "      <td>0.051666</td>\n",
       "      <td>0.068540</td>\n",
       "      <td>0.353056</td>\n",
       "      <td>-0.073502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>qlH5-G576fQ</td>\n",
       "      <td>0.526200</td>\n",
       "      <td>-0.049693</td>\n",
       "      <td>0.016550</td>\n",
       "      <td>0.315958</td>\n",
       "      <td>0.019130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>uLXyFJEbj_s</td>\n",
       "      <td>0.260255</td>\n",
       "      <td>-0.025891</td>\n",
       "      <td>-0.207168</td>\n",
       "      <td>-0.112689</td>\n",
       "      <td>-0.079400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>A3riThai7MU</td>\n",
       "      <td>0.423757</td>\n",
       "      <td>-0.044581</td>\n",
       "      <td>0.021968</td>\n",
       "      <td>0.242374</td>\n",
       "      <td>0.011728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CrfnkgwU978</td>\n",
       "      <td>0.271992</td>\n",
       "      <td>0.087251</td>\n",
       "      <td>-0.001373</td>\n",
       "      <td>0.018363</td>\n",
       "      <td>-0.053234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AS6cUYyA_qI</td>\n",
       "      <td>0.033672</td>\n",
       "      <td>0.102116</td>\n",
       "      <td>-0.005850</td>\n",
       "      <td>0.004774</td>\n",
       "      <td>0.003761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             component_1  component_2  component_3  component_4  component_5\n",
       "video_id                                                                    \n",
       "_5DXs8xxaMU     0.313722    -0.037640     0.067371    -0.253653     0.093814\n",
       "DNrMPF3I_bs     0.369401    -0.036863     0.036569    -0.298927     0.008293\n",
       "TwN8soCzjPM     0.512953    -0.060678     0.366408    -0.085243    -0.241111\n",
       "8OMUdYoIJhI     0.365220    -0.035835     0.084806     0.093842     0.099401\n",
       "xk_MHfOAfRQ     0.443260     0.051666     0.068540     0.353056    -0.073502\n",
       "...                  ...          ...          ...          ...          ...\n",
       "qlH5-G576fQ     0.526200    -0.049693     0.016550     0.315958     0.019130\n",
       "uLXyFJEbj_s     0.260255    -0.025891    -0.207168    -0.112689    -0.079400\n",
       "A3riThai7MU     0.423757    -0.044581     0.021968     0.242374     0.011728\n",
       "CrfnkgwU978     0.271992     0.087251    -0.001373     0.018363    -0.053234\n",
       "AS6cUYyA_qI     0.033672     0.102116    -0.005850     0.004774     0.003761\n",
       "\n",
       "[277 rows x 5 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_lsa = pd.DataFrame(doc_topic,\n",
    "                             index=df['video_id'],\n",
    "                             columns = [\"component_1\",\"component_2\", \"component_3\",\"component_4\", \"component_5\"])\n",
    "doc_topic_lsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.97231186, 0.68426166, 0.17952577, 0.93627735,\n",
       "        0.87603034],\n",
       "       [0.97231186, 1.        , 0.74072561, 0.2383418 , 0.86494457,\n",
       "        0.88806269],\n",
       "       [0.68426166, 0.74072561, 1.        , 0.80877308, 0.68394879,\n",
       "        0.92116077],\n",
       "       [0.17952577, 0.2383418 , 0.80877308, 1.        , 0.3207386 ,\n",
       "        0.60785513],\n",
       "       [0.93627735, 0.86494457, 0.68394879, 0.3207386 , 1.        ,\n",
       "        0.89214641],\n",
       "       [0.87603034, 0.88806269, 0.92116077, 0.60785513, 0.89214641,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity((doc_topic_lsa.values[0], \n",
    "                   doc_topic_lsa.values[1], \n",
    "                   doc_topic_lsa.values[3],  \n",
    "                   doc_topic_lsa.values[4], \n",
    "                   doc_topic_lsa.values[5], \n",
    "                   doc_topic_lsa.values[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosine_similarity((doc_topic_lsa.values[0], doc_topic_lsa.values[6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF (Non-Negative Matrix Factorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(5)\n",
    "doc_topic = nmf_model.fit_transform(doc_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaah</th>\n",
       "      <th>aaaaaw</th>\n",
       "      <th>aaahhh</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aasimm</th>\n",
       "      <th>ab</th>\n",
       "      <th>abacus</th>\n",
       "      <th>abanda</th>\n",
       "      <th>abandon</th>\n",
       "      <th>...</th>\n",
       "      <th>منتننتب</th>\n",
       "      <th>منني</th>\n",
       "      <th>يبخؤن</th>\n",
       "      <th>يسي</th>\n",
       "      <th>يمنن</th>\n",
       "      <th>くじょう</th>\n",
       "      <th>不好意思</th>\n",
       "      <th>法國人</th>\n",
       "      <th>阴茎病毒</th>\n",
       "      <th>ﻻهص</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>component_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>component_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>component_3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>component_4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>component_5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12987 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              aa  aaaaah  aaaaaw  aaahhh  aaron  aasimm     ab  abacus  \\\n",
       "component_1  0.0     0.0     0.0     0.0  0.003   0.000  0.008   0.001   \n",
       "component_2  0.0     0.0     0.0     0.0  0.000   0.000  0.000   0.000   \n",
       "component_3  0.0     0.0     0.0     0.0  0.000   0.000  0.003   0.000   \n",
       "component_4  0.0     0.0     0.0     0.0  0.000   0.001  0.000   0.000   \n",
       "component_5  0.0     0.0     0.0     0.0  0.001   0.000  0.002   0.000   \n",
       "\n",
       "             abanda  abandon  ...  منتننتب  منني  يبخؤن  يسي  يمنن  くじょう  \\\n",
       "component_1   0.001    0.000  ...      0.0   0.0    0.0  0.0   0.0   0.0   \n",
       "component_2   0.010    0.000  ...      0.0   0.0    0.0  0.0   0.0   0.0   \n",
       "component_3   0.000    0.000  ...      0.0   0.0    0.0  0.0   0.0   0.0   \n",
       "component_4   0.000    0.011  ...      0.0   0.0    0.0  0.0   0.0   0.0   \n",
       "component_5   0.000    0.000  ...      0.0   0.0    0.0  0.0   0.0   0.0   \n",
       "\n",
       "             不好意思    法國人  阴茎病毒  ﻻهص  \n",
       "component_1   0.0  0.000   0.0  0.0  \n",
       "component_2   0.0  0.000   0.0  0.0  \n",
       "component_3   0.0  0.000   0.0  0.0  \n",
       "component_4   0.0  0.001   0.0  0.0  \n",
       "component_5   0.0  0.000   0.0  0.0  \n",
       "\n",
       "[5 rows x 12987 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word = pd.DataFrame(nmf_model.components_.round(3),\n",
    "             index = [\"component_1\",\"component_2\", \"component_3\",\"component_4\", \"component_5\"],\n",
    "             columns = vectorizer.get_feature_names())\n",
    "topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "know, gon, peopl, good, man, realli, time, ve, ll, mean, come, guy, look, talk\n",
      "\n",
      "Topic  1\n",
      "laughter, fool, obvious, surpri, plea, check, myka, marfa, sub, switch, flip, tintin, god, visit\n",
      "\n",
      "Topic  2\n",
      "toilet, paper, gon, ass, need, hack, panic, day, shelv, hand, groceri, wipe, john, store\n",
      "\n",
      "Topic  3\n",
      "peopl, china, countri, trump, presid, test, case, number, american, know, infect, chine, come, spread\n",
      "\n",
      "Topic  4\n",
      "home, stay, plea, wash, hand, let, distanc, spread, bore, social, insid, eat, isol, yes\n"
     ]
    }
   ],
   "source": [
    "display_topics(nmf_model, vectorizer.get_feature_names(), 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component_1</th>\n",
       "      <th>component_2</th>\n",
       "      <th>component_3</th>\n",
       "      <th>component_4</th>\n",
       "      <th>component_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>_5DXs8xxaMU</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.13633</td>\n",
       "      <td>0.19867</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DNrMPF3I_bs</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00066</td>\n",
       "      <td>0.20240</td>\n",
       "      <td>0.19646</td>\n",
       "      <td>0.03069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TwN8soCzjPM</td>\n",
       "      <td>0.13429</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.03938</td>\n",
       "      <td>0.36182</td>\n",
       "      <td>0.02518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8OMUdYoIJhI</td>\n",
       "      <td>0.16283</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.05823</td>\n",
       "      <td>0.05626</td>\n",
       "      <td>0.00207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xk_MHfOAfRQ</td>\n",
       "      <td>0.34669</td>\n",
       "      <td>0.04909</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>qlH5-G576fQ</td>\n",
       "      <td>0.30730</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.04917</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.03118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>uLXyFJEbj_s</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00246</td>\n",
       "      <td>0.23338</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>A3riThai7MU</td>\n",
       "      <td>0.21781</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.05861</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CrfnkgwU978</td>\n",
       "      <td>0.06823</td>\n",
       "      <td>0.06130</td>\n",
       "      <td>0.09577</td>\n",
       "      <td>0.02117</td>\n",
       "      <td>0.04522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AS6cUYyA_qI</td>\n",
       "      <td>0.01399</td>\n",
       "      <td>0.06486</td>\n",
       "      <td>0.00141</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             component_1  component_2  component_3  component_4  component_5\n",
       "video_id                                                                    \n",
       "_5DXs8xxaMU      0.00000      0.00000      0.13633      0.19867      0.00000\n",
       "DNrMPF3I_bs      0.00000      0.00066      0.20240      0.19646      0.03069\n",
       "TwN8soCzjPM      0.13429      0.00000      0.03938      0.36182      0.02518\n",
       "8OMUdYoIJhI      0.16283      0.00000      0.05823      0.05626      0.00207\n",
       "xk_MHfOAfRQ      0.34669      0.04909      0.00000      0.00000      0.00000\n",
       "...                  ...          ...          ...          ...          ...\n",
       "qlH5-G576fQ      0.30730      0.00000      0.04917      0.00000      0.03118\n",
       "uLXyFJEbj_s      0.00000      0.00246      0.23338      0.00000      0.00000\n",
       "A3riThai7MU      0.21781      0.00000      0.05861      0.00000      0.00000\n",
       "CrfnkgwU978      0.06823      0.06130      0.09577      0.02117      0.04522\n",
       "AS6cUYyA_qI      0.01399      0.06486      0.00141      0.00000      0.00000\n",
       "\n",
       "[277 rows x 5 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_nmf = pd.DataFrame(doc_topic.round(5),\n",
    "                             index=df['video_id'],\n",
    "                             columns = [\"component_1\",\"component_2\", \"component_3\",\"component_4\", \"component_5\"])\n",
    "doc_topic_nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.97453512],\n",
       "       [0.97453512, 1.        ]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity((doc_topic_nmf.values[0], doc_topic_nmf.values[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.89487066],\n",
       "       [0.89487066, 1.        ]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity((doc_topic_nmf.values[0], doc_topic_nmf.values[26]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change vectorizer!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic = lda.fit_transform(dtm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LatentDirichletAllocation.score of LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=5, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=None,\n",
       "                          topic_word_prior=None, total_samples=1000000.0,\n",
       "                          verbose=0)>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaah</th>\n",
       "      <th>aaaaaw</th>\n",
       "      <th>aaahhh</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aasimm</th>\n",
       "      <th>ab</th>\n",
       "      <th>abacus</th>\n",
       "      <th>abanda</th>\n",
       "      <th>abandon</th>\n",
       "      <th>...</th>\n",
       "      <th>منتننتب</th>\n",
       "      <th>منني</th>\n",
       "      <th>يبخؤن</th>\n",
       "      <th>يسي</th>\n",
       "      <th>يمنن</th>\n",
       "      <th>くじょう</th>\n",
       "      <th>不好意思</th>\n",
       "      <th>法國人</th>\n",
       "      <th>阴茎病毒</th>\n",
       "      <th>ﻻهص</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>component_1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>component_2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.213</td>\n",
       "      <td>2.435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>component_3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.202</td>\n",
       "      <td>3.965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>component_4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>34.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.163</td>\n",
       "      <td>0.200</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>32.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>component_5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13089 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              aa  aaaaah  aaaaaw  aaahhh  aaron  aasimm   ab  abacus  abanda  \\\n",
       "component_1  0.2     0.2     0.2     0.2    0.2     0.2  2.2     0.2   0.223   \n",
       "component_2  0.2     0.2     0.2     0.2    1.2     0.2  0.2     1.2   0.213   \n",
       "component_3  0.2     0.2     0.2     0.2    0.2     0.2  1.2     0.2   0.202   \n",
       "component_4  1.2     1.2     1.2     1.2    3.2    34.2  1.2     0.2   1.163   \n",
       "component_5  0.2     0.2     0.2     0.2    1.2     0.2  0.2     0.2   0.200   \n",
       "\n",
       "             abandon  ...  منتننتب  منني  يبخؤن  يسي  يمنن  くじょう  不好意思   法國人  \\\n",
       "component_1    0.200  ...      0.2   0.2    0.2  0.2   0.2   0.2   0.2   0.2   \n",
       "component_2    2.435  ...      0.2   0.2    0.2  0.2   0.2   0.2   0.2   0.2   \n",
       "component_3    3.965  ...      0.2   0.2    0.2  0.2   0.2   0.2   0.2   0.2   \n",
       "component_4    0.200  ...      1.2   1.2    1.2  1.2   1.2   1.2   3.2  32.2   \n",
       "component_5    0.200  ...      0.2   0.2    0.2  0.2   0.2   0.2   0.2   0.2   \n",
       "\n",
       "             阴茎病毒  ﻻهص  \n",
       "component_1   0.2  0.2  \n",
       "component_2   0.2  0.2  \n",
       "component_3   0.2  0.2  \n",
       "component_4   1.2  1.2  \n",
       "component_5   0.2  0.2  \n",
       "\n",
       "[5 rows x 13089 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word = pd.DataFrame(lda.components_.round(3),\n",
    "             index = [\"component_1\",\"component_2\", \"component_3\",\"component_4\", \"component_5\"],\n",
    "             columns = vectorizer.get_feature_names())\n",
    "topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "yeah, know, think, peopl, mean, right, thing, make, realli, ve, way, time, got, someth, laughter\n",
      "\n",
      "Topic  1\n",
      "know, peopl, come, say, oh, yeah, right, year, na, think, want, time, got, ve, look\n",
      "\n",
      "Topic  2\n",
      "know, peopl, na, right, gon, got, say, thing, want, time, think, ve, realli, need, come\n",
      "\n",
      "Topic  3\n",
      "georgehotz, lul, pogchamp, claim, lol, georg, make, dj, vicio, use, work, stream, theonlymonka, harbad, know\n",
      "\n",
      "Topic  4\n",
      "know, peopl, time, say, right, think, okay, thank, thing, ve, na, look, want, ll, mask\n"
     ]
    }
   ],
   "source": [
    "display_topics(lda, vectorizer.get_feature_names(), 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20000031, 0.20000031, 0.20000031, ..., 0.20000702, 0.20000031,\n",
       "        0.20000031],\n",
       "       [0.20054092, 0.20054092, 0.20054092, ..., 0.21819025, 0.20054092,\n",
       "        0.20054092],\n",
       "       [0.20000031, 0.20000031, 0.20000031, ..., 0.20000713, 0.20000031,\n",
       "        0.20000031],\n",
       "       [0.20000031, 0.20000031, 0.20000031, ..., 0.20000714, 0.20000031,\n",
       "        0.20000031],\n",
       "       [0.20025767, 0.20025767, 0.20025767, ..., 0.20737333, 0.20025767,\n",
       "        0.20025767]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component_1</th>\n",
       "      <th>component_2</th>\n",
       "      <th>component_3</th>\n",
       "      <th>component_4</th>\n",
       "      <th>component_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>_5DXs8xxaMU</td>\n",
       "      <td>0.01856</td>\n",
       "      <td>0.92575</td>\n",
       "      <td>0.01856</td>\n",
       "      <td>0.01856</td>\n",
       "      <td>0.01856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DNrMPF3I_bs</td>\n",
       "      <td>0.01291</td>\n",
       "      <td>0.94838</td>\n",
       "      <td>0.01290</td>\n",
       "      <td>0.01290</td>\n",
       "      <td>0.01290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TwN8soCzjPM</td>\n",
       "      <td>0.01373</td>\n",
       "      <td>0.94509</td>\n",
       "      <td>0.01373</td>\n",
       "      <td>0.01373</td>\n",
       "      <td>0.01373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8OMUdYoIJhI</td>\n",
       "      <td>0.01509</td>\n",
       "      <td>0.93965</td>\n",
       "      <td>0.01509</td>\n",
       "      <td>0.01509</td>\n",
       "      <td>0.01509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xk_MHfOAfRQ</td>\n",
       "      <td>0.01924</td>\n",
       "      <td>0.92306</td>\n",
       "      <td>0.01923</td>\n",
       "      <td>0.01923</td>\n",
       "      <td>0.01923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>qlH5-G576fQ</td>\n",
       "      <td>0.01129</td>\n",
       "      <td>0.95486</td>\n",
       "      <td>0.01128</td>\n",
       "      <td>0.01128</td>\n",
       "      <td>0.01128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>uLXyFJEbj_s</td>\n",
       "      <td>0.01758</td>\n",
       "      <td>0.92969</td>\n",
       "      <td>0.01758</td>\n",
       "      <td>0.01758</td>\n",
       "      <td>0.01758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>A3riThai7MU</td>\n",
       "      <td>0.02080</td>\n",
       "      <td>0.91681</td>\n",
       "      <td>0.02080</td>\n",
       "      <td>0.02080</td>\n",
       "      <td>0.02080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CrfnkgwU978</td>\n",
       "      <td>0.02080</td>\n",
       "      <td>0.91683</td>\n",
       "      <td>0.02079</td>\n",
       "      <td>0.02079</td>\n",
       "      <td>0.02079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AS6cUYyA_qI</td>\n",
       "      <td>0.59164</td>\n",
       "      <td>0.29395</td>\n",
       "      <td>0.03800</td>\n",
       "      <td>0.03800</td>\n",
       "      <td>0.03841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             component_1  component_2  component_3  component_4  component_5\n",
       "video_id                                                                    \n",
       "_5DXs8xxaMU      0.01856      0.92575      0.01856      0.01856      0.01856\n",
       "DNrMPF3I_bs      0.01291      0.94838      0.01290      0.01290      0.01290\n",
       "TwN8soCzjPM      0.01373      0.94509      0.01373      0.01373      0.01373\n",
       "8OMUdYoIJhI      0.01509      0.93965      0.01509      0.01509      0.01509\n",
       "xk_MHfOAfRQ      0.01924      0.92306      0.01923      0.01923      0.01923\n",
       "...                  ...          ...          ...          ...          ...\n",
       "qlH5-G576fQ      0.01129      0.95486      0.01128      0.01128      0.01128\n",
       "uLXyFJEbj_s      0.01758      0.92969      0.01758      0.01758      0.01758\n",
       "A3riThai7MU      0.02080      0.91681      0.02080      0.02080      0.02080\n",
       "CrfnkgwU978      0.02080      0.91683      0.02079      0.02079      0.02079\n",
       "AS6cUYyA_qI      0.59164      0.29395      0.03800      0.03800      0.03841\n",
       "\n",
       "[277 rows x 5 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_lda = pd.DataFrame(doc_topic.round(5),\n",
    "                             index=df['video_id'],\n",
    "                             columns = [\"component_1\",\"component_2\", \"component_3\",\"component_4\", \"component_5\"])\n",
    "doc_topic_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.96752052],\n",
       "       [0.96752052, 1.        ]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity((doc_topic_nmf.values[0], doc_topic_nmf.values[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.84052477],\n",
       "       [0.84052477, 1.        ]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity((doc_topic_nmf.values[0], doc_topic_nmf.values[136]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
